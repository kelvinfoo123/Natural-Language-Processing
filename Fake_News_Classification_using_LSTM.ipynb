{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcvVU8PA0r9RDOJ24sJopn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kelvinfoo123/Natural-Language-Processing/blob/main/Fake_News_Classification_using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I experiment using LSTM to classify fake news by looking at the headline. \n",
        "\n"
      ],
      "metadata": {
        "id": "WyrCZyBRamwF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoidouTgafQM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news = pd.read_csv(\"data.csv\")\n",
        "news.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "l6OtjSh-bOlc",
        "outputId": "191d3263-ffba-4083-cdda-33058985ca3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                URLs  \\\n",
              "0  http://www.bbc.com/news/world-us-canada-414191...   \n",
              "1  https://www.reuters.com/article/us-filmfestiva...   \n",
              "2  https://www.nytimes.com/2017/10/09/us/politics...   \n",
              "3  https://www.reuters.com/article/us-mexico-oil-...   \n",
              "4  http://www.cnn.com/videos/cnnmoney/2017/10/08/...   \n",
              "\n",
              "                                            Headline  \\\n",
              "0         Four ways Bob Corker skewered Donald Trump   \n",
              "1  Linklater's war veteran comedy speaks to moder...   \n",
              "2  Trump’s Fight With Corker Jeopardizes His Legi...   \n",
              "3  Egypt's Cheiron wins tie-up with Pemex for Mex...   \n",
              "4        Jason Aldean opens 'SNL' with Vegas tribute   \n",
              "\n",
              "                                                Body  Label  \n",
              "0  Image copyright Getty Images\\nOn Sunday mornin...      1  \n",
              "1  LONDON (Reuters) - “Last Flag Flying”, a comed...      1  \n",
              "2  The feud broke into public view last week when...      1  \n",
              "3  MEXICO CITY (Reuters) - Egypt’s Cheiron Holdin...      1  \n",
              "4  Country singer Jason Aldean, who was performin...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58538b5c-56a6-49fd-982a-039f77d50118\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URLs</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://www.bbc.com/news/world-us-canada-414191...</td>\n",
              "      <td>Four ways Bob Corker skewered Donald Trump</td>\n",
              "      <td>Image copyright Getty Images\\nOn Sunday mornin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.reuters.com/article/us-filmfestiva...</td>\n",
              "      <td>Linklater's war veteran comedy speaks to moder...</td>\n",
              "      <td>LONDON (Reuters) - “Last Flag Flying”, a comed...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.nytimes.com/2017/10/09/us/politics...</td>\n",
              "      <td>Trump’s Fight With Corker Jeopardizes His Legi...</td>\n",
              "      <td>The feud broke into public view last week when...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.reuters.com/article/us-mexico-oil-...</td>\n",
              "      <td>Egypt's Cheiron wins tie-up with Pemex for Mex...</td>\n",
              "      <td>MEXICO CITY (Reuters) - Egypt’s Cheiron Holdin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://www.cnn.com/videos/cnnmoney/2017/10/08/...</td>\n",
              "      <td>Jason Aldean opens 'SNL' with Vegas tribute</td>\n",
              "      <td>Country singer Jason Aldean, who was performin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58538b5c-56a6-49fd-982a-039f77d50118')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58538b5c-56a6-49fd-982a-039f77d50118 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58538b5c-56a6-49fd-982a-039f77d50118');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news.isnull().sum() # No null values in the headline. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCwh18FWcKnr",
        "outputId": "2afa28b4-1a8c-43bb-f082-cd3d1879f95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "URLs         0\n",
              "Headline     0\n",
              "Body        21\n",
              "Label        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = news['Headline']\n",
        "y = news['Label']\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdRSKFNvcaFK",
        "outputId": "1d645be7-714a-42ac-bd46-4e0cc1b0def8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4009,)\n",
            "(4009,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Preprocessing**"
      ],
      "metadata": {
        "id": "QUk2zDJDe4b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk \n",
        "import re \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88mojAe9dTVK",
        "outputId": "c4f157b4-cdbc-4340-e2aa-781247867608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = []\n",
        "\n",
        "for i in range(0, len(X)): \n",
        "  review = re.sub('[^a-zA-Z]', ' ', X[i]) # For every headline, if the character is not a word, replace with ' '. \n",
        "  review = review.lower() # Make all words lower case. The same word in different cases are treated as different words. \n",
        "  review = review.split()\n",
        "  review = [word for word in review if not word in stopwords.words('english')] # Remove stopwords \n",
        "  review = [stemmer.stem(word) for word in review] # Stemming \n",
        "\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)"
      ],
      "metadata": {
        "id": "3ndJCrQyfLOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,11): \n",
        "  print(corpus[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xfWACNagPl4",
        "outputId": "d3910582-53cc-413d-914e-3df6ea954146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linklat war veteran comedi speak modern america say star\n",
            "trump fight corker jeopard legisl agenda\n",
            "egypt cheiron win tie pemex mexican onshor oil field\n",
            "jason aldean open snl vega tribut\n",
            "jetnat fanduel leagu week\n",
            "kansa tri tax plan similar trump fail\n",
            "india rbi chief growth import cost inflat newspap\n",
            "epa chief sign rule clean power plan exit tuesday\n",
            "talk sale air berlin plane easyjet risk collaps report\n",
            "u presid donald trump quietli sign law allow warrantless search part va dc md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Hot Representation**\n",
        "\n",
        "One-hot encodes a text into a list of word indexes of size n, where n is the size of the vocab. \n",
        "\n",
        "Reason for encoding is to apply embedding as embedding requires input data to be integer encoded. "
      ],
      "metadata": {
        "id": "b_QeDXascyyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ],
      "metadata": {
        "id": "neDE2JVRc3Ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary size \n",
        "voc_size = 10000"
      ],
      "metadata": {
        "id": "1J8RV7mvdPwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_repre = [one_hot(words, voc_size) for words in corpus]\n",
        "\n",
        "for i in range(11): \n",
        "  print(onehot_repre[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-wuFZgIghgE",
        "outputId": "96642ce1-2b08-4288-b435-367fc1b3857f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5158, 6484, 6823, 1668, 6327, 7425, 7412]\n",
            "[1926, 9453, 7126, 2586, 650, 4102, 1761, 625, 1150]\n",
            "[7412, 8097, 1668, 7841, 2446, 3487]\n",
            "[9447, 1487, 9641, 1285, 7460, 1575, 3554, 8378, 9970]\n",
            "[2313, 7904, 2066, 7133, 7700, 6097]\n",
            "[4913, 2247, 4938, 7649]\n",
            "[7637, 4985, 4370, 8277, 2331, 7412, 2751]\n",
            "[4202, 8294, 7452, 2864, 3376, 9890, 4293, 7879]\n",
            "[1087, 7452, 6186, 6904, 4795, 6410, 8277, 6735, 6574]\n",
            "[3723, 9017, 2443, 4556, 3568, 2867, 5526, 8141, 593]\n",
            "[5026, 8720, 7425, 7412, 8876, 6186, 8525, 4206, 3298, 7037, 6436, 7052, 3169, 4887]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Padding Sequences**\n",
        "\n",
        "LSTM require that input sequences have the same length. We make all input sequences have the same length by padding 0 to the input until they have the stated length. "
      ],
      "metadata": {
        "id": "loqT3vESj0tU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Library for padding \n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences "
      ],
      "metadata": {
        "id": "p8PaKaaRkDW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length = 30 # Require that all inputs have length 30 \n",
        "\n",
        "padded = pad_sequences(onehot_repre, padding = 'pre', maxlen = length) # Padding = 'pre' means pad in front of the input. \n",
        "\n",
        "for i in range(11): \n",
        "  print(padded[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnnNMiPWkUT3",
        "outputId": "4eaadc61-6950-4c08-f9a4-ef31d4a0d55a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0 5158 6484 6823 1668 6327\n",
            " 7425 7412]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0 1926 9453 7126 2586  650 4102 1761\n",
            "  625 1150]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0 7412 8097 1668 7841\n",
            " 2446 3487]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0 9447 1487 9641 1285 7460 1575 3554\n",
            " 8378 9970]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0 2313 7904 2066 7133\n",
            " 7700 6097]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0 4913 2247\n",
            " 4938 7649]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0 7637 4985 4370 8277 2331\n",
            " 7412 2751]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0 4202 8294 7452 2864 3376 9890\n",
            " 4293 7879]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0 1087 7452 6186 6904 4795 6410 8277\n",
            " 6735 6574]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0 3723 9017 2443 4556 3568 2867 5526\n",
            " 8141  593]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0 5026 8720 7425 7412 8876 6186 8525 4206 3298 7037 6436 7052\n",
            " 3169 4887]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building Model**\n",
        "\n",
        "Before running LSTM, we need an embedding layer. Compared to traditional bag of words model where representation vectors are sparse due to large vocabularies, words are represented by dense vectors in an embedding. \n",
        "\n",
        "The embedding layer requires that the input data be integer encoded, so that each word is represented by a unique integer. \n",
        "\n",
        "The embedding layer has 3 arguments: \n",
        "\n",
        "\n",
        "*   input_dim: Size of vocab\n",
        "*   output_dim: Size of vector space in which word will be embedded. \n",
        "*   input_length: Length of input sentence \n",
        "\n",
        "\n",
        "The embedding layer will be trained as part of the neural network. The output is a 2D vector with one embedding for each word in the input. \n"
      ],
      "metadata": {
        "id": "n2_GqWqVkzlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers \n",
        "from tensorflow.keras.layers import Embedding \n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import LSTM \n",
        "from tensorflow.keras.layers import Dense, Dropout"
      ],
      "metadata": {
        "id": "P3jkan-Dn9Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_final = np.array(padded)\n",
        "y_final = np.array(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_final, y_final, test_size = 0.3, random_state = 42)"
      ],
      "metadata": {
        "id": "FdH275b-oyU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_size = 40 # Size of vector space in which word will be embedded.\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(voc_size, vector_size, input_length = length))\n",
        "model.add(LSTM(100)) # One LSTM layer with 100 neurons \n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "6Zm-0la7k2wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "pkr5Gc0iolPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10, batch_size = 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAauZN0XpUNm",
        "outputId": "d66a968a-1094-45cc-e728-20949f5c129c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "44/44 [==============================] - 5s 60ms/step - loss: 0.6771 - accuracy: 0.5638 - val_loss: 0.6025 - val_accuracy: 0.7240\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 2s 45ms/step - loss: 0.4269 - accuracy: 0.8532 - val_loss: 0.4282 - val_accuracy: 0.7955\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 2s 45ms/step - loss: 0.2182 - accuracy: 0.9227 - val_loss: 0.4030 - val_accuracy: 0.8155\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 3s 76ms/step - loss: 0.1179 - accuracy: 0.9629 - val_loss: 0.4571 - val_accuracy: 0.8288\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.0655 - accuracy: 0.9804 - val_loss: 0.5188 - val_accuracy: 0.8254\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 3s 58ms/step - loss: 0.0382 - accuracy: 0.9882 - val_loss: 0.5901 - val_accuracy: 0.8279\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.0280 - accuracy: 0.9929 - val_loss: 0.5163 - val_accuracy: 0.8180\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 2s 46ms/step - loss: 0.0249 - accuracy: 0.9947 - val_loss: 0.6961 - val_accuracy: 0.8229\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 2s 53ms/step - loss: 0.0081 - accuracy: 0.9986 - val_loss: 1.0120 - val_accuracy: 0.8246\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 2s 45ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 0.9572 - val_accuracy: 0.8238\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa52d567490>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training accuracy is much higher than the test accuracy. This might be a sign of overfitting. We implement dropout or regularization. "
      ],
      "metadata": {
        "id": "vY-c5GW9plQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(voc_size, vector_size, input_length = length))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation = 'sigmoid', kernel_regularizer = regularizers.l2(0.01)))"
      ],
      "metadata": {
        "id": "ccTR0o7gpvAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Jrq2Blawp_cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10, batch_size = 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBEsa5aWqAsD",
        "outputId": "69f5cf81-baa6-4eb8-fc96-b2df11a05488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "44/44 [==============================] - 5s 63ms/step - loss: 0.7054 - accuracy: 0.5314 - val_loss: 0.6941 - val_accuracy: 0.6916\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.6157 - accuracy: 0.7324 - val_loss: 0.5090 - val_accuracy: 0.7714\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.3859 - accuracy: 0.8614 - val_loss: 0.4559 - val_accuracy: 0.7972\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.2574 - accuracy: 0.9141 - val_loss: 0.4441 - val_accuracy: 0.8105\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.1908 - accuracy: 0.9408 - val_loss: 0.4303 - val_accuracy: 0.8155\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 2s 47ms/step - loss: 0.1415 - accuracy: 0.9629 - val_loss: 0.4467 - val_accuracy: 0.8171\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 0.1233 - accuracy: 0.9701 - val_loss: 0.5175 - val_accuracy: 0.8213\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 2s 47ms/step - loss: 0.0874 - accuracy: 0.9840 - val_loss: 0.5668 - val_accuracy: 0.8238\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 0.0666 - accuracy: 0.9850 - val_loss: 0.5663 - val_accuracy: 0.8246\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.0650 - accuracy: 0.9882 - val_loss: 0.5634 - val_accuracy: 0.8204\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa52a357bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bidirectional LSTM**"
      ],
      "metadata": {
        "id": "wJEzhNbbNxXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Bidirectional"
      ],
      "metadata": {
        "id": "82ylqbutN3nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_size = 40 \n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(voc_size, vector_size, input_length = length))\n",
        "model.add(Bidirectional(LSTM(100)))\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "aaYXDF3NN-Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "_oH5NrQmONcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10, batch_size = 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoqJ1CuFOON9",
        "outputId": "25b65c83-fd77-4cba-be72-09ed2179561e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "44/44 [==============================] - 6s 74ms/step - loss: 0.6861 - accuracy: 0.5859 - val_loss: 0.6513 - val_accuracy: 0.6185\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 2s 54ms/step - loss: 0.4859 - accuracy: 0.8001 - val_loss: 0.4184 - val_accuracy: 0.8030\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 2s 53ms/step - loss: 0.2015 - accuracy: 0.9241 - val_loss: 0.4790 - val_accuracy: 0.8180\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 2s 52ms/step - loss: 0.1043 - accuracy: 0.9661 - val_loss: 0.5114 - val_accuracy: 0.8271\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 2s 53ms/step - loss: 0.0699 - accuracy: 0.9779 - val_loss: 0.5646 - val_accuracy: 0.8379\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 2s 52ms/step - loss: 0.0399 - accuracy: 0.9904 - val_loss: 0.6368 - val_accuracy: 0.8437\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 2s 54ms/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 0.6957 - val_accuracy: 0.8437\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 2s 53ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.8779 - val_accuracy: 0.8371\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 2s 53ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.7634 - val_accuracy: 0.8313\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 2s 52ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.9971 - val_accuracy: 0.8421\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f829ae174d0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}